{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from load_data import load_csv_to_dict\n",
    "import alphalens as al\n",
    "\n",
    "def calculate_mom6_parameterized(master_data, lookback_period=126, winsorize_lower=0.01, winsorize_upper=0.99):\n",
    "    \"\"\"\n",
    "    Parameterized version of MOM6 calculation with simplified parameters\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    master_data : dict\n",
    "        Dictionary containing market data with 'master_close' DataFrame\n",
    "    lookback_period : int\n",
    "        Number of days to look back for momentum calculation\n",
    "    winsorize_lower : float\n",
    "        Lower percentile for winsorization (0 to 1)\n",
    "    winsorize_upper : float\n",
    "        Upper percentile for winsorization (0 to 1)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Factor values for each asset and date\n",
    "    \"\"\"\n",
    "    if not isinstance(master_data, dict) or 'master_close' not in master_data:\n",
    "        raise ValueError(\"master_data must be a dictionary containing 'master_close'\")\n",
    "        \n",
    "    if not (0 <= winsorize_lower < winsorize_upper <= 1):\n",
    "        raise ValueError(\"Invalid winsorization bounds\")\n",
    "        \n",
    "    # Get close prices\n",
    "    close = master_data['master_close'].copy()\n",
    "    \n",
    "    # Calculate daily returns - handle inf values\n",
    "    daily_returns = close.pct_change().replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Calculate momentum using rolling window\n",
    "    def mom6_calculation(window):\n",
    "        clean_window = window.dropna()\n",
    "        if len(clean_window) < lookback_period:\n",
    "            return np.nan\n",
    "        try:\n",
    "            cum_return = (1 + clean_window).prod() - 1\n",
    "            return cum_return if np.isfinite(cum_return) else np.nan\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    # Apply rolling calculation with progress bar\n",
    "    factor = pd.DataFrame(index=daily_returns.index, columns=daily_returns.columns)\n",
    "    for col in tqdm(daily_returns.columns, desc=\"Calculating momentum\"):\n",
    "        factor[col] = daily_returns[col].rolling(\n",
    "            window=lookback_period,\n",
    "            min_periods=lookback_period\n",
    "        ).apply(mom6_calculation)\n",
    "    \n",
    "    # Shift by 1 to avoid look-ahead bias\n",
    "    factor = factor.shift(1)\n",
    "    \n",
    "    # Cross-sectional standardization with minimum sample size check\n",
    "    min_samples = max(10, int(0.1 * factor.shape[1]))  # At least 10 stocks or 10% of universe\n",
    "    \n",
    "    for dt in factor.index:\n",
    "        valid_data = factor.loc[dt].dropna()\n",
    "        if len(valid_data) >= min_samples:\n",
    "            mean = valid_data.mean()\n",
    "            std = valid_data.std()\n",
    "            if std > 0:\n",
    "                factor.loc[dt] = (factor.loc[dt] - mean) / std\n",
    "                \n",
    "    # Winsorize extreme values\n",
    "    valid_data = factor.stack().dropna()\n",
    "    if len(valid_data) > 0:\n",
    "        lower = valid_data.quantile(winsorize_lower)\n",
    "        upper = valid_data.quantile(winsorize_upper)\n",
    "        factor = factor.clip(lower=lower, upper=upper)\n",
    "    \n",
    "    # Add basic statistics logging\n",
    "    stats_summary = factor.describe()\n",
    "    print(\"\\nFactor Statistics:\")\n",
    "    print(stats_summary)\n",
    "    \n",
    "    missing_pct = factor.isnull().mean().mean() * 100\n",
    "    print(f\"\\nMissing Values: {missing_pct:.2f}%\")\n",
    "    \n",
    "    return factor\n",
    "\n",
    "def evaluate_performance(factor, price_df):\n",
    "    \"\"\"\n",
    "    Performance evaluation using IC and returns spread with enhanced error handling\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    factor : pd.DataFrame\n",
    "        Factor values for each asset and date\n",
    "    price_df : pd.DataFrame\n",
    "        Price data for assets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Performance metrics including IC and Sharpe ratio\n",
    "    \"\"\"\n",
    "    if factor.isnull().all().all():\n",
    "        print(\"Warning: Factor contains all NaN values\")\n",
    "        return {'ic_mean': -np.inf, 'sharpe': -np.inf}\n",
    "        \n",
    "    # Prepare data for alphalens\n",
    "    factor_data = factor.stack().reset_index()\n",
    "    factor_data.columns = ['date', 'asset', 'factor']\n",
    "    factor_data = factor_data.set_index(['date', 'asset'])\n",
    "    \n",
    "    try:\n",
    "        # Get clean factor data with more robust parameters\n",
    "        factor_data_aligned = al.utils.get_clean_factor_and_forward_returns(\n",
    "            factor=factor_data,\n",
    "            prices=price_df,\n",
    "            periods=(1, 5, 10, 20),\n",
    "            quantiles=5,  # Reduced from 10 to 5 for more robust quantile formation\n",
    "            max_loss=0.35  # More conservative max loss threshold\n",
    "        )\n",
    "        \n",
    "        # Calculate IC with proper handling of edge cases\n",
    "        ic = al.performance.factor_information_coefficient(factor_data_aligned)\n",
    "        ic_mean = ic.mean().mean()\n",
    "        ic_std = ic.std().mean()\n",
    "        ic_ir = ic_mean / ic_std if ic_std > 0 else -np.inf\n",
    "        \n",
    "        # Calculate returns with proper error handling\n",
    "        returns = al.performance.factor_returns(factor_data_aligned)\n",
    "        returns = returns.fillna(0)\n",
    "        \n",
    "        if len(returns) > 252:  # Ensure we have at least one year of data\n",
    "            annual_returns = returns.mean() * 252\n",
    "            annual_vol = returns.std() * np.sqrt(252)\n",
    "            sharpe = (annual_returns / annual_vol).mean()\n",
    "        else:\n",
    "            print(\"Warning: Insufficient data for reliable Sharpe ratio calculation\")\n",
    "            sharpe = -np.inf\n",
    "            \n",
    "        return {\n",
    "            'ic_mean': ic_mean if not np.isnan(ic_mean) else -np.inf,\n",
    "            'ic_ir': ic_ir,\n",
    "            'sharpe': sharpe,\n",
    "            'data_coverage': len(returns) / 252  # Years of data coverage\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in performance evaluation: {str(e)}\")\n",
    "        return {\n",
    "            'ic_mean': -np.inf,\n",
    "            'ic_ir': -np.inf,\n",
    "            'sharpe': -np.inf,\n",
    "            'data_coverage': 0\n",
    "        }\n",
    "\n",
    "def optimize_parameters(master_data, price_df):\n",
    "    \"\"\"\n",
    "    Parameter optimization with enhanced parameter ranges and progress tracking\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    master_data : dict\n",
    "        Dictionary containing market data\n",
    "    price_df : pd.DataFrame\n",
    "        Price data for assets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Results of parameter optimization\n",
    "    \"\"\"\n",
    "    # Define parameter ranges with more granularity\n",
    "    lookback_periods = [5, 10, 20]\n",
    "    winsorize_lowers = [0.01]\n",
    "    winsorize_uppers = [0.95]\n",
    "    \n",
    "    # Create parameter combinations\n",
    "    param_combinations = list(itertools.product(\n",
    "        lookback_periods,\n",
    "        winsorize_lowers,\n",
    "        winsorize_uppers\n",
    "    ))\n",
    "    \n",
    "    # Filter invalid combinations\n",
    "    param_combinations = [\n",
    "        (l, wl, wu) for l, wl, wu in param_combinations\n",
    "        if wl < wu  # Ensure lower bound is less than upper bound\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Use tqdm for progress tracking\n",
    "    for lookback, win_lower, win_upper in tqdm(param_combinations, desc=\"Optimizing parameters\"):\n",
    "        print(f\"\\nTesting: lookback={lookback}, winsorize_lower={win_lower}, winsorize_upper={win_upper}\")\n",
    "        \n",
    "        try:\n",
    "            # Calculate factor\n",
    "            factor = calculate_mom6_parameterized(\n",
    "                master_data,\n",
    "                lookback_period=lookback,\n",
    "                winsorize_lower=win_lower,\n",
    "                winsorize_upper=win_upper\n",
    "            )\n",
    "            \n",
    "            # Evaluate performance\n",
    "            perf = evaluate_performance(factor, price_df)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'lookback_period': lookback,\n",
    "                'winsorize_lower': win_lower,\n",
    "                'winsorize_upper': win_upper,\n",
    "                'ic_mean': perf['ic_mean'],\n",
    "                'ic_ir': perf.get('ic_ir', -np.inf),\n",
    "                'sharpe': perf['sharpe'],\n",
    "                'data_coverage': perf.get('data_coverage', 0)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with parameters {lookback}, {win_lower}, {win_upper}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Convert results to DataFrame and sort by multiple metrics\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['combined_score'] = (\n",
    "        results_df['ic_mean'].rank(pct=True) +\n",
    "        results_df['sharpe'].rank(pct=True) +\n",
    "        results_df['data_coverage'].rank(pct=True)\n",
    "    ) / 3\n",
    "    \n",
    "    return results_df.sort_values('combined_score', ascending=False)\n",
    "\n",
    "def plot_optimization_results(results_df):\n",
    "    \"\"\"\n",
    "    Enhanced visualization of optimization results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : pd.DataFrame\n",
    "        Results from parameter optimization\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        Figure containing the plots\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: IC Mean vs Lookback Period\n",
    "    ax1 = plt.subplot(221)\n",
    "    sns.boxplot(data=results_df, x='lookback_period', y='ic_mean', ax=ax1)\n",
    "    ax1.set_title('IC Mean vs Lookback Period')\n",
    "    ax1.set_xlabel('Lookback Period (days)')\n",
    "    ax1.set_ylabel('IC Mean')\n",
    "    \n",
    "    # Plot 2: Sharpe vs Lookback Period\n",
    "    ax2 = plt.subplot(222)\n",
    "    sns.boxplot(data=results_df, x='lookback_period', y='sharpe', ax=ax2)\n",
    "    ax2.set_title('Sharpe Ratio vs Lookback Period')\n",
    "    ax2.set_xlabel('Lookback Period (days)')\n",
    "    ax2.set_ylabel('Sharpe Ratio')\n",
    "    \n",
    "    # Plot 3: Heatmap of Combined Score\n",
    "    ax3 = plt.subplot(212)\n",
    "    pivot_data = results_df.pivot_table(\n",
    "        index='winsorize_lower',\n",
    "        columns='lookback_period',\n",
    "        values='combined_score',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='RdYlBu_r', ax=ax3)\n",
    "    ax3.set_title('Combined Score Heatmap')\n",
    "    ax3.set_xlabel('Lookback Period (days)')\n",
    "    ax3.set_ylabel('Winsorize Lower Bound')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def run_optimization(master_data, price_df):\n",
    "    \"\"\"\n",
    "    Run the complete optimization process with enhanced reporting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    master_data : dict\n",
    "        Dictionary containing market data\n",
    "    price_df : pd.DataFrame\n",
    "        Price data for assets\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Optimization results\n",
    "    \"\"\"\n",
    "    print(\"Starting parameter optimization...\")\n",
    "    results = optimize_parameters(master_data, price_df)\n",
    "    \n",
    "    print(\"\\nTop 5 parameter combinations by combined score:\")\n",
    "    print(results.head().to_string())\n",
    "    \n",
    "    print(\"\\nBest parameters by IC:\")\n",
    "    print(results.loc[results['ic_mean'].idxmax()].to_string())\n",
    "    \n",
    "    print(\"\\nBest parameters by Sharpe:\")\n",
    "    print(results.loc[results['sharpe'].idxmax()].to_string())\n",
    "    \n",
    "    # Create and save plots\n",
    "    fig = plot_optimization_results(results)\n",
    "    plt.savefig('optimization_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/mouyasushi/Desktop/Factor/alpha_lens/alphalens/alphalens/my_research/data\"\n",
    "\n",
    "master_data = load_csv_to_dict (data_path)\n",
    "price_df = master_data['master_close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_time(master_data, price_df, train_ratio=0.7):  # change ratio here \n",
    "    \"\"\"\n",
    "    Split data into in-sample and out-of-sample periods based on time\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    master_data : dict\n",
    "        Dictionary containing OHLC DataFrames\n",
    "    price_df : pd.DataFrame\n",
    "        Price DataFrame for factor analysis\n",
    "    train_ratio : float\n",
    "        Ratio for training data (e.g., 0.7 for 70-30 split)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Contains in-sample and out-of-sample data\n",
    "    \"\"\"\n",
    "    # Calculate split point\n",
    "    split_index = int(len(price_df) * train_ratio)\n",
    "    split_date = price_df.index[split_index]\n",
    "    \n",
    "    print(f\"Split date: {split_date}\")\n",
    "    \n",
    "    # Split master_data\n",
    "    insample_master = {}\n",
    "    outsample_master = {}\n",
    "    \n",
    "    for key, df in master_data.items():\n",
    "        insample_master[key] = df.loc[:split_date]\n",
    "        outsample_master[key] = df.loc[split_date:]\n",
    "    \n",
    "    # Split price_df\n",
    "    insample_price = price_df.loc[:split_date]\n",
    "    outsample_price = price_df.loc[split_date:]\n",
    "    \n",
    "    # Print split info\n",
    "    print(f\"\\nIn-sample period: {insample_price.index[0]} to {insample_price.index[-1]}\")\n",
    "    print(f\"Out-of-sample period: {outsample_price.index[0]} to {outsample_price.index[-1]}\")\n",
    "    print(f\"\\nIn-sample shape: {insample_price.shape}\")\n",
    "    print(f\"Out-of-sample shape: {outsample_price.shape}\")\n",
    "    \n",
    "    return {\n",
    "        'insample': {\n",
    "            'master_data': insample_master,\n",
    "            'price_df': insample_price\n",
    "        },\n",
    "        'outsample': {\n",
    "            'master_data': outsample_master,\n",
    "            'price_df': outsample_price\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split date: 2023-11-16 00:00:00\n",
      "\n",
      "In-sample period: 2021-10-14 00:00:00 to 2023-11-16 00:00:00\n",
      "Out-of-sample period: 2023-11-16 00:00:00 to 2024-10-14 00:00:00\n",
      "\n",
      "In-sample shape: (511, 405)\n",
      "Out-of-sample shape: (219, 405)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "split_data = split_data_time(master_data, price_df)\n",
    "\n",
    "# Access the split data\n",
    "insample_master_data = split_data['insample']['master_data']\n",
    "insample_price_df = split_data['insample']['price_df']\n",
    "\n",
    "outsample_master_data = split_data['outsample']['master_data']\n",
    "outsample_price_df = split_data['outsample']['price_df']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implmentation OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing parameters:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: lookback=5, winsorize_lower=0.01, winsorize_upper=0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating momentum: 100%|██████████| 405/405 [00:21<00:00, 19.06it/s]\n",
      "Optimizing parameters:   0%|          | 0/3 [01:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Use insample data to optimize parameters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsample_master_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsample_price_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 2. Get best parameters from in-sample results\u001b[39;00m\n\u001b[1;32m      5\u001b[0m best_params \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mloc[results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mic_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()]\n",
      "Cell \u001b[0;32mIn[1], line 302\u001b[0m, in \u001b[0;36mrun_optimization\u001b[0;34m(master_data, price_df)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03mRun the complete optimization process with enhanced reporting\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    Optimization results\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting parameter optimization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 302\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaster_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTop 5 parameter combinations by combined score:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mto_string())\n",
      "Cell \u001b[0;32mIn[1], line 204\u001b[0m, in \u001b[0;36moptimize_parameters\u001b[0;34m(master_data, price_df)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting: lookback=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlookback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, winsorize_lower=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwin_lower\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, winsorize_upper=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwin_upper\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Calculate factor\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     factor \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mom6_parameterized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlookback_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwinsorize_lower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_lower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwinsorize_upper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_upper\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# Evaluate performance\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     perf \u001b[38;5;241m=\u001b[39m evaluate_performance(factor, price_df)\n",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m, in \u001b[0;36mcalculate_mom6_parameterized\u001b[0;34m(master_data, lookback_period, winsorize_lower, winsorize_upper)\u001b[0m\n\u001b[1;32m     72\u001b[0m         std \u001b[38;5;241m=\u001b[39m valid_data\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m std \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m             \u001b[43mfactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (factor\u001b[38;5;241m.\u001b[39mloc[dt] \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Winsorize extreme values\u001b[39;00m\n\u001b[1;32m     77\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m factor\u001b[38;5;241m.\u001b[39mstack()\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pandas/core/indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1942\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pandas/core/indexing.py:2016\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;66;03m# We are setting multiple columns in a single row.\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ilocs, value):\n\u001b[0;32m-> 2016\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(pi) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;66;03m# This is a setitem-with-expansion, see\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;66;03m#  test_loc_setitem_empty_append_expands_rows_mixed_dtype\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;66;03m# e.g. df = DataFrame(columns=[\"x\", \"y\"])\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m     \u001b[38;5;66;03m#  df[\"x\"] = df[\"x\"].astype(np.int64)\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m#  df.loc[:, \"x\"] = [1, 2, 3]\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pandas/core/indexing.py:2164\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   2160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39misetitem(loc, value)\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2162\u001b[0m     \u001b[38;5;66;03m# set value into the column (first attempting to operate inplace, then\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m     \u001b[38;5;66;03m#  falling back to casting if necessary)\u001b[39;00m\n\u001b[0;32m-> 2164\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241m.\u001b[39miloc[loc]\n\u001b[1;32m   2165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mvoid:\n\u001b[1;32m   2166\u001b[0m         \u001b[38;5;66;03m# This means we're expanding, with multiple columns, e.g.\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m         \u001b[38;5;66;03m#     df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6]})\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[38;5;66;03m# Here, we replace those temporary `np.void` columns with\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m         \u001b[38;5;66;03m# columns of the appropriate dtype, based on `value`.\u001b[39;00m\n\u001b[1;32m   2172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[:, loc] \u001b[38;5;241m=\u001b[39m construct_1d_array_from_inferred_fill_value(\n\u001b[1;32m   2173\u001b[0m             value, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   2174\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pandas/core/generic.py:6460\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6432\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   6433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtypes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   6434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6435\u001b[0m \u001b[38;5;124;03m    Return the dtypes in the DataFrame.\u001b[39;00m\n\u001b[1;32m   6436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6458\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   6459\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6460\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(data, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.12/site-packages/pandas/core/internals/managers.py:288\u001b[0m, in \u001b[0;36mBaseBlockManager.get_dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dtypes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mobject_]:\n\u001b[0;32m--> 288\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1. Use insample data to optimize parameters\n",
    "results = run_optimization(insample_master_data, insample_price_df)\n",
    "\n",
    "# 2. Get best parameters from in-sample results\n",
    "best_params = results.loc[results['ic_mean'].idxmax()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Optimized perf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantstats as qs\n",
    "import pandas as pd\n",
    "\n",
    "def create_performance_report(returns, benchmark_rets=None, positions=None, output_filename='analysis.html'):\n",
    "    \"\"\"\n",
    "    Create a comprehensive performance report using QuantStats.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : pd.Series\n",
    "        Daily returns of the strategy, noncumulative\n",
    "    benchmark_rets : pd.Series, optional\n",
    "        Daily returns of the benchmark\n",
    "    positions : pd.DataFrame, optional\n",
    "        Daily position values (not directly used in QuantStats but can be analyzed separately)\n",
    "    output_filename : str, optional\n",
    "        Name of the output HTML file\n",
    "    \"\"\"\n",
    "    # Extend pandas functionality with QuantStats\n",
    "    qs.extend_pandas()\n",
    "    \n",
    "    # If benchmark is provided, create a full comparison report\n",
    "    if benchmark_rets is not None:\n",
    "        # Create HTML report comparing strategy to benchmark\n",
    "        qs.reports.html(returns, \n",
    "                       benchmark_rets, \n",
    "                       output=output_filename,\n",
    "                       title='Strategy Analysis')\n",
    "    else:\n",
    "        # Create HTML report for strategy alone\n",
    "        qs.reports.html(returns, \n",
    "                       output=output_filename,\n",
    "                       title='Strategy Analysis')\n",
    "    \n",
    "    # Print basic metrics to console\n",
    "    print(\"\\nBasic Performance Metrics:\")\n",
    "    print(\"-------------------------\")\n",
    "    print(f\"Sharpe Ratio: {qs.stats.sharpe(returns):.2f}\")\n",
    "    print(f\"Max Drawdown: {qs.stats.max_drawdown(returns):.2%}\")\n",
    "    print(f\"Win Rate: {qs.stats.win_rate(returns):.2%}\")\n",
    "    \n",
    "    # If positions are provided, we can analyze them separately\n",
    "    if positions is not None:\n",
    "        print(\"\\nPosition Summary:\")\n",
    "        print(\"----------------\")\n",
    "        print(f\"Average Position Count: {positions.count(axis=1).mean():.2f}\")\n",
    "        print(f\"Max Position Count: {positions.count(axis=1).max()}\")\n",
    "\n",
    "\n",
    "# For additional specific metrics:\n",
    "def print_detailed_metrics(returns, benchmark_rets=None):\n",
    "    \"\"\"Print detailed performance metrics\"\"\"\n",
    "    print(\"\\nDetailed Metrics:\")\n",
    "    print(\"----------------\")\n",
    "    metrics = {\n",
    "        'Annual Return': qs.stats.cagr(returns),\n",
    "        'Volatility': qs.stats.volatility(returns),\n",
    "    }\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{metric}: {value:.2%}\" if 'Duration' not in metric else f\"{metric}: {value:.0f} days\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mouyasushi/Desktop/Factor/alpha_lens/alphalens/alphalens/my_research/data/aligned_benchmark.csv'\n",
    "\n",
    "# Ensure aligned_benchmark has consistent data types\n",
    "aligned_benchmark = pd.read_csv(path)\n",
    "\n",
    "# Correct data types in aligned_benchmark\n",
    "aligned_benchmark['column_name'] = aligned_benchmark['column_name'].astype(float)  # Update 'column_name' as necessary\n",
    "\n",
    "# Ensure factor_data is processed correctly\n",
    "factor_data = optimal_factor.stack().reset_index()\n",
    "factor_data.columns = ['date', 'asset', 'factor']\n",
    "\n",
    "# Convert 'factor' to numeric to avoid string-related issues\n",
    "factor_data['factor'] = pd.to_numeric(factor_data['factor'], errors='coerce')\n",
    "\n",
    "# Ensure proper alignment of factors and returns\n",
    "factor_data = factor_data.set_index(['date', 'asset'])\n",
    "\n",
    "factor_data_aligned = al.utils.get_clean_factor_and_forward_returns(\n",
    "    factor=factor_data,\n",
    "    prices=price_df,\n",
    "    periods=periods,\n",
    "    quantiles=10,\n",
    "    max_loss=0.5\n",
    ")\n",
    "\n",
    "# Generate returns and positions with proper data handling\n",
    "optimal_returns, optimal_positions, _ = al.performance.create_pyfolio_input(\n",
    "    factor_data_aligned,\n",
    "    period='1D',\n",
    "    capital=1_000_000,\n",
    "    long_short=True,\n",
    "    group_neutral=False,\n",
    "    equal_weight=True,\n",
    "    quantiles=[1, 10]\n",
    ")\n",
    "\n",
    "# Handle performance report generation\n",
    "create_performance_report(\n",
    "    returns=optimal_returns,\n",
    "    benchmark_rets=aligned_benchmark,\n",
    "    positions=optimal_positions,\n",
    "    output_filename='optimized_strategy_analysis.html'\n",
    ")\n",
    "\n",
    "# Print additional metrics\n",
    "print_detailed_metrics(optimal_returns, aligned_benchmark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
