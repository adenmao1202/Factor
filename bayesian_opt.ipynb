{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence, plot_objective\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_objective_function(master_data, price_df):\n",
    "    \"\"\"\n",
    "    Create the objective function for Bayesian optimization\n",
    "    \"\"\"\n",
    "    # Define the parameter space\n",
    "    space = [\n",
    "        Integer(60, 252, name='lookback_period'),  # 3M to 12M\n",
    "        Real(0.01, 0.1, name='winsorize_lower'),   # 1% to 10%\n",
    "        Real(0.9, 0.99, name='winsorize_upper')    # 90% to 99%\n",
    "    ]\n",
    "\n",
    "    # Define the objective function\n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        try:\n",
    "            # Calculate factor with current parameters\n",
    "            factor = calculate_mom6_parameterized(\n",
    "                master_data,\n",
    "                lookback_period=params['lookback_period'],\n",
    "                winsorize_lower=params['winsorize_lower'],\n",
    "                winsorize_upper=params['winsorize_upper']\n",
    "            )\n",
    "            \n",
    "            # Evaluate performance\n",
    "            perf = evaluate_performance(factor, price_df)\n",
    "            \n",
    "            # We want to maximize Sharpe, so return negative for minimization\n",
    "            return -perf['sharpe']  # or use -perf['ic_mean'] if preferred\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with parameters {params}: {str(e)}\")\n",
    "            return 0.0  # Return poor score for failed evaluations\n",
    "    \n",
    "    return objective, space\n",
    "\n",
    "def run_bayesian_optimization(master_data, price_df, n_calls=50):\n",
    "    \"\"\"\n",
    "    Run Bayesian optimization for factor parameters\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    master_data : dict\n",
    "        Dictionary containing OHLC data\n",
    "    price_df : pd.DataFrame\n",
    "        Price data for factor evaluation\n",
    "    n_calls : int\n",
    "        Number of optimization iterations\n",
    "    \"\"\"\n",
    "    # Create objective function and space\n",
    "    objective, space = create_objective_function(master_data, price_df)\n",
    "    \n",
    "    # Run optimization\n",
    "    print(\"Starting Bayesian Optimization...\")\n",
    "    result = gp_minimize(\n",
    "        func=objective,\n",
    "        dimensions=space,\n",
    "        n_calls=n_calls,\n",
    "        n_random_starts=10,\n",
    "        noise=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Extract results\n",
    "    best_params = {\n",
    "        'lookback_period': result.x[0],\n",
    "        'winsorize_lower': result.x[1],\n",
    "        'winsorize_upper': result.x[2]\n",
    "    }\n",
    "    \n",
    "    print(\"\\nOptimization Results:\")\n",
    "    print(\"Best parameters found:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Best Sharpe ratio: {-result.fun}\")  # Negative because we minimized negative Sharpe\n",
    "    \n",
    "    # Plot optimization results\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_convergence(result)\n",
    "    plt.title('Convergence plot')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_objective(result, show_points=True)\n",
    "    plt.title('Parameter space')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return result, best_params\n",
    "\n",
    "def analyze_optimization_results(result, master_data, price_df):\n",
    "    \"\"\"\n",
    "    Analyze the results of Bayesian optimization\n",
    "    \"\"\"\n",
    "    # Get parameter names\n",
    "    param_names = ['lookback_period', 'winsorize_lower', 'winsorize_upper']\n",
    "    \n",
    "    # Create DataFrame of all evaluations\n",
    "    evaluations = pd.DataFrame([\n",
    "        {param_names[i]: x[i] for i in range(len(param_names))}\n",
    "        for x in result.x_iters\n",
    "    ])\n",
    "    evaluations['score'] = -np.array(result.func_vals)  # Convert back to Sharpe ratio\n",
    "    \n",
    "    # Calculate performance with best parameters\n",
    "    best_params = {\n",
    "        'lookback_period': result.x[0],\n",
    "        'winsorize_lower': result.x[1],\n",
    "        'winsorize_upper': result.x[2]\n",
    "    }\n",
    "    \n",
    "    best_factor = calculate_mom6_parameterized(master_data, **best_params)\n",
    "    \n",
    "    # Prepare data for alphalens analysis\n",
    "    factor_data = best_factor.stack().reset_index()\n",
    "    factor_data.columns = ['date', 'asset', 'factor']\n",
    "    factor_data = factor_data.set_index(['date', 'asset'])\n",
    "    \n",
    "    factor_data_aligned = al.utils.get_clean_factor_and_forward_returns(\n",
    "        factor=factor_data,\n",
    "        prices=price_df,\n",
    "        periods=(1, 5, 10, 20),\n",
    "        quantiles=10,\n",
    "        max_loss=0.5\n",
    "    )\n",
    "    \n",
    "    # Create tear sheet\n",
    "    al.tears.create_full_tear_sheet(\n",
    "        factor_data=factor_data_aligned,\n",
    "        long_short=True,\n",
    "        group_neutral=False\n",
    "    )\n",
    "    \n",
    "    return evaluations\n",
    "\n",
    "# Example usage:\n",
    "def optimize_factor_bayesian(master_data, price_df):\n",
    "    \"\"\"\n",
    "    Complete pipeline for Bayesian optimization of factor parameters\n",
    "    \"\"\"\n",
    "    # Run optimization\n",
    "    result, best_params = run_bayesian_optimization(master_data, price_df)\n",
    "    \n",
    "    # Analyze results\n",
    "    evaluations = analyze_optimization_results(result, master_data, price_df)\n",
    "    \n",
    "    return result, best_params, evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = \n",
    "price_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run optimization\n",
    "result, best_params, evaluations = optimize_factor_bayesian(master_data, price_df)\n",
    "\n",
    "# View all evaluations\n",
    "print(\"\\nAll evaluations:\")\n",
    "print(evaluations.sort_values('score', ascending=False).head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
